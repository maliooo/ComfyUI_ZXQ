import os
import base64
from pathlib import Path
from typing import Union, List, Dict, Optional
from openai import OpenAI
from PIL import Image
import io
import shutil
import traceback
from tqdm import tqdm
import torch
import numpy as np
from .config import SUPPORTED_MODELS, OPENROUTE_CONFIG
import sys

# ä½ çš„å…¶ä»–ä»£ç 
print("ç¨‹åºå¼€å§‹è¿è¡Œ...")

class OpenRouteImageAnalysis:
    """
    OpenRouteå›¾ç‰‡åˆ†æèŠ‚ç‚¹
    æ”¯æŒURLå›¾ç‰‡å’Œæœ¬åœ°å›¾ç‰‡çš„åˆ†æï¼Œè°ƒç”¨OpenRoute APIè¿›è¡Œå›¾ç‰‡ç†è§£
    """
    
    @classmethod
    def INPUT_TYPES(s):
        default_model = OPENROUTE_CONFIG["default_model"]
        default_max_tokens = OPENROUTE_CONFIG["default_max_tokens"]
        default_temperature = OPENROUTE_CONFIG["default_temperature"]
        default_max_width = OPENROUTE_CONFIG["default_max_width"]
        default_max_height = OPENROUTE_CONFIG["default_max_height"]
        default_quality = OPENROUTE_CONFIG["default_quality"]
        default_base_url = OPENROUTE_CONFIG["base_url"]
        default_site_url = OPENROUTE_CONFIG["site_url"]
        default_site_name = OPENROUTE_CONFIG["site_name"]
        default_api_key = OPENROUTE_CONFIG["api_key"]

        return {
            "required": {
                "image": ("IMAGE",),
                "prompt": ("STRING", {
                    "default": "è¯·åˆ†æè¿™å¼ å›¾ç‰‡çš„å†…å®¹",
                    "multiline": True,
                    "tooltip": "åˆ†æå›¾ç‰‡çš„æç¤ºè¯"
                }),
                "api_key": ("STRING", {
                    "default": default_api_key,
                    "tooltip": "OpenRoute APIå¯†é’¥"
                }),
                "model": (SUPPORTED_MODELS, {
                    "default": default_model,
                    "tooltip": "ä½¿ç”¨çš„æ¨¡å‹åç§°"
                }),
                "max_tokens": ("INT", {
                    "default": default_max_tokens,
                    "min": 100,
                    "max": 4000,
                    "step": 100,
                    "tooltip": "æœ€å¤§è¾“å‡ºtokenæ•°"
                }),
                "temperature": ("FLOAT", {
                    "default": default_temperature,
                    "min": 0.0,
                    "max": 2.0,
                    "step": 0.1,
                    "tooltip": "ç”Ÿæˆæ¸©åº¦ï¼Œæ§åˆ¶éšæœºæ€§"
                }),
                "max_width": ("INT", {
                    "default": default_max_width,
                    "min": 512,
                    "max": 2048,
                    "step": 64,
                    "tooltip": "å›¾ç‰‡æœ€å¤§å®½åº¦ï¼ˆåƒç´ ï¼‰"
                }),
                "max_height": ("INT", {
                    "default": default_max_height,
                    "min": 512,
                    "max": 2048,
                    "step": 64,
                    "tooltip": "å›¾ç‰‡æœ€å¤§é«˜åº¦ï¼ˆåƒç´ ï¼‰"
                }),
                "quality": ("INT", {
                    "default": default_quality,
                    "min": 50,
                    "max": 100,
                    "step": 5,
                    "tooltip": "JPEGè´¨é‡ï¼ˆ1-100ï¼‰"
                }),
            },
            "optional": {
                "base_url": ("STRING", {
                    "default": default_base_url,
                    "tooltip": "APIåŸºç¡€URL"
                }),
                "site_url": ("STRING", {
                    "default": default_site_url,
                    "tooltip": "ç½‘ç«™URLï¼ˆç”¨äºOpenRouteræ’åï¼‰"
                }),
                "site_name": ("STRING", {
                    "default": default_site_name,
                    "tooltip": "ç½‘ç«™åç§°ï¼ˆç”¨äºOpenRouteræ’åï¼‰"
                }),
                "output_filename": ("STRING", {
                    "default": "generated_image.png",
                    "tooltip": "è¾“å‡ºå›¾ç‰‡æ–‡ä»¶å"
                }),
            }
        }

    RETURN_TYPES = ("STRING", "IMAGE",)
    RETURN_NAMES = ("analysis_result", "generated_image",)
    FUNCTION = "execute"

    _NODE_ZXQ = "OpenRouteå›¾ç‰‡åˆ†æ OpenRoute Image Analysis"
    DESCRIPTION = "ä½¿ç”¨OpenRoute APIåˆ†æå›¾ç‰‡å†…å®¹ï¼Œæ”¯æŒå¤šç§AIæ¨¡å‹è¿›è¡Œå›¾ç‰‡ç†è§£å’Œç”Ÿæˆ"
    CATEGORY = "ZXQ/LLM/å›¾ç‰‡åˆ†æ"

    def execute(self, image, prompt, api_key, model, max_tokens, temperature, max_width, max_height, quality, 
                base_url=None, site_url=None, site_name=None, 
                output_filename="generated_image.png"):
        """
        æ‰§è¡Œå›¾ç‰‡åˆ†æ
        
        Args:
            image: è¾“å…¥çš„å›¾ç‰‡å¼ é‡
            prompt: åˆ†ææç¤ºè¯
            api_key: OpenRoute APIå¯†é’¥
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°
            max_tokens: æœ€å¤§è¾“å‡ºtokenæ•°
            temperature: ç”Ÿæˆæ¸©åº¦
            max_width: å›¾ç‰‡æœ€å¤§å®½åº¦
            max_height: å›¾ç‰‡æœ€å¤§é«˜åº¦
            quality: JPEGè´¨é‡
            base_url: APIåŸºç¡€URL
            site_url: ç½‘ç«™URL
            site_name: ç½‘ç«™åç§°
            output_filename: è¾“å‡ºå›¾ç‰‡æ–‡ä»¶å
            
        Returns:
            analysis_result: åˆ†æç»“æœæ–‡æœ¬
            generated_image: ç”Ÿæˆçš„å›¾ç‰‡ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        """
        # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤å€¼
        if base_url is None:
            base_url = OPENROUTE_CONFIG["base_url"]
        if site_url is None:
            site_url = OPENROUTE_CONFIG["site_url"]
        if site_name is None:
            site_name = OPENROUTE_CONFIG["site_name"]
            
        try:
            # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
            client = OpenAI(
                base_url=base_url,
                api_key=api_key
            )
            
            # å°†torchå¼ é‡è½¬æ¢ä¸ºPILå›¾ç‰‡
            pil_image = self._tensor_to_pil(image)
            
            # è°ƒæ•´å›¾ç‰‡å°ºå¯¸
            pil_image = self._resize_image(pil_image, max_width, max_height)
            
            # ç¼–ç ä¸ºbase64
            base64_image = self._encode_image_to_base64(pil_image, quality)
            
            # åˆ›å»ºå›¾ç‰‡å†…å®¹
            image_content = {
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{base64_image}"
                }
            }
            
            # åˆ›å»ºæ¶ˆæ¯
            messages = [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": prompt
                        },
                        image_content
                    ]
                }
            ]
            
            # è°ƒç”¨API
            print(f"ğŸ¤– æ­£åœ¨ä½¿ç”¨ {model} æ¨¡å‹åˆ†æå›¾ç‰‡...")
            completion = client.chat.completions.create(
                model=model,
                messages=messages,
                max_tokens=max_tokens,
                temperature=temperature
            )
            
            # è·å–åˆ†æç»“æœ
            analysis_result = completion.choices[0].message.content
            print(f"âœ… å›¾ç‰‡åˆ†æå®Œæˆ")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ç”Ÿæˆçš„å›¾ç‰‡
            generated_image = None
            if hasattr(completion.choices[0].message, 'images') and completion.choices[0].message.images:
                print(f"ğŸ¨ æ£€æµ‹åˆ°ç”Ÿæˆçš„å›¾ç‰‡ï¼Œæ­£åœ¨å¤„ç†...")
                generated_image = self._process_generated_images(completion.choices[0].message.images, output_filename)
            
            return (analysis_result, generated_image if generated_image is not None else image)
            
        except Exception as e:
            error_msg = f"å›¾ç‰‡åˆ†æå¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            traceback.print_exc()
            return (error_msg, image)
    
    def _tensor_to_pil(self, image_tensor):
        """å°†torchå¼ é‡è½¬æ¢ä¸ºPILå›¾ç‰‡"""
        # ç¡®ä¿å›¾ç‰‡å¼ é‡æ ¼å¼æ­£ç¡® (batch, height, width, channels)
        if len(image_tensor.shape) == 4:
            image_tensor = image_tensor[0]  # å–ç¬¬ä¸€ä¸ªbatch
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„å¹¶ç¡®ä¿å€¼åœ¨0-255èŒƒå›´å†…
        if image_tensor.dtype == torch.float32:
            image_array = (image_tensor.cpu().numpy() * 255).astype(np.uint8)
        else:
            image_array = image_tensor.cpu().numpy().astype(np.uint8)
        
        # åˆ›å»ºPILå›¾ç‰‡
        pil_image = Image.fromarray(image_array)
        return pil_image
    
    def _resize_image(self, pil_image, max_width, max_height):
        """è°ƒæ•´å›¾ç‰‡å°ºå¯¸ï¼Œä¿æŒæ¯”ä¾‹"""
        original_width, original_height = pil_image.size
        
        # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
        if max_width and max_height:
            scale_factor = min(max_width / original_width, max_height / original_height)
        elif max_width:
            scale_factor = max_width / original_width
        elif max_height:
            scale_factor = max_height / original_height
        else:
            return pil_image
        
        # å¦‚æœå›¾ç‰‡å·²ç»å°äºé™åˆ¶å°ºå¯¸ï¼Œåˆ™ä¸ç¼©æ”¾
        if scale_factor >= 1.0:
            print(f"ğŸ“ å›¾ç‰‡å°ºå¯¸ {original_width}x{original_height} æ— éœ€ç¼©æ”¾")
            return pil_image
        
        # è®¡ç®—æ–°å°ºå¯¸
        new_width = int(original_width * scale_factor)
        new_height = int(original_height * scale_factor)
        
        # ç¼©æ”¾å›¾ç‰‡
        resized_image = pil_image.resize((new_width, new_height), Image.Resampling.LANCZOS)
        print(f"ğŸ“ å›¾ç‰‡å·²ç¼©æ”¾: {original_width}x{original_height} -> {new_width}x{new_height}")
        
        return resized_image
    
    def _encode_image_to_base64(self, pil_image, quality):
        """å°†PILå›¾ç‰‡ç¼–ç ä¸ºbase64å­—ç¬¦ä¸²"""
        # ç¡®ä¿å›¾ç‰‡æ˜¯RGBæ¨¡å¼
        if pil_image.mode != 'RGB':
            pil_image = pil_image.convert('RGB')
        
        # è½¬æ¢ä¸ºå­—èŠ‚æµ
        img_byte_arr = io.BytesIO()
        pil_image.save(img_byte_arr, format='JPEG', quality=quality, optimize=True)
        img_byte_arr.seek(0)
        
        return base64.b64encode(img_byte_arr.getvalue()).decode('utf-8')
    
    def _process_generated_images(self, images_data, output_filename):
        """å¤„ç†APIè¿”å›çš„ç”Ÿæˆå›¾ç‰‡"""
        try:
            for i, image_data in enumerate(images_data):
                if 'image_url' in image_data and 'url' in image_data['image_url']:
                    base64_string = image_data['image_url']['url']
                    
                    # æå–base64æ•°æ®
                    if ',' in base64_string:
                        base64_data = base64_string.split(',')[1]
                    else:
                        base64_data = base64_string
                    
                    # è§£ç ä¸ºå›¾ç‰‡å­—èŠ‚
                    image_bytes = base64.b64decode(base64_data)
                    
                    # åˆ›å»ºPILå›¾ç‰‡
                    pil_image = Image.open(io.BytesIO(image_bytes))
                    
                    # è½¬æ¢ä¸ºRGBæ¨¡å¼
                    if pil_image.mode != 'RGB':
                        pil_image = pil_image.convert('RGB')
                    
                    # è½¬æ¢ä¸ºtorchå¼ é‡
                    image_array = np.array(pil_image)
                    image_tensor = torch.from_numpy(image_array).float() / 255.0
                    
                    # æ·»åŠ batchç»´åº¦
                    image_tensor = image_tensor.unsqueeze(0)
                    
                    print(f"ğŸ¨ æˆåŠŸå¤„ç†ç”Ÿæˆçš„å›¾ç‰‡ {i+1}")
                    return image_tensor
            
            print("âš ï¸ æœªæ‰¾åˆ°æœ‰æ•ˆçš„ç”Ÿæˆå›¾ç‰‡æ•°æ®")
            return None
            
        except Exception as e:
            print(f"âŒ å¤„ç†ç”Ÿæˆå›¾ç‰‡å¤±è´¥: {e}")
            return None

# æ‰¹é‡å¤„ç†èŠ‚ç‚¹
class OpenRouteBatchImageAnalysis:
    """
    OpenRouteæ‰¹é‡å›¾ç‰‡åˆ†æèŠ‚ç‚¹
    æ”¯æŒæ‰¹é‡å¤„ç†å¤šå¼ å›¾ç‰‡
    """
    
    @classmethod
    def INPUT_TYPES(s):
        default_model = OPENROUTE_CONFIG["default_model"]
        default_max_tokens = OPENROUTE_CONFIG["default_max_tokens"]
        default_temperature = OPENROUTE_CONFIG["default_temperature"]
        default_base_url = OPENROUTE_CONFIG["base_url"]
        default_api_key = OPENROUTE_CONFIG["api_key"]
        
        return {
            "required": {
                "images": ("IMAGE",),
                "prompt": ("STRING", {
                    "default": "è¯·åˆ†æè¿™å¼ å›¾ç‰‡çš„å†…å®¹",
                    "multiline": True,
                    "tooltip": "åˆ†æå›¾ç‰‡çš„æç¤ºè¯"
                }),
                "api_key": ("STRING", {
                    "default": default_api_key,
                    "tooltip": "OpenRoute APIå¯†é’¥"
                }),
                "model": ("STRING", {
                    "default": default_model,
                    "tooltip": "ä½¿ç”¨çš„æ¨¡å‹åç§°"
                }),
                "max_tokens": ("INT", {
                    "default": default_max_tokens,
                    "min": 100,
                    "max": 4000,
                    "step": 100,
                    "tooltip": "æœ€å¤§è¾“å‡ºtokenæ•°"
                }),
                "temperature": ("FLOAT", {
                    "default": default_temperature,
                    "min": 0.0,
                    "max": 2.0,
                    "step": 0.1,
                    "tooltip": "ç”Ÿæˆæ¸©åº¦ï¼Œæ§åˆ¶éšæœºæ€§"
                }),
            },
            "optional": {
                "base_url": ("STRING", {
                    "default": default_base_url,
                    "tooltip": "APIåŸºç¡€URL"
                }),
            }
        }

    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("batch_results",)
    FUNCTION = "execute"

    _NODE_ZXQ = "OpenRouteæ‰¹é‡å›¾ç‰‡åˆ†æ OpenRoute Batch Image Analysis"
    DESCRIPTION = "æ‰¹é‡ä½¿ç”¨OpenRoute APIåˆ†æå¤šå¼ å›¾ç‰‡å†…å®¹"
    CATEGORY = "ZXQ/LLM/å›¾ç‰‡åˆ†æ"

    def execute(self, images, prompt, api_key, model, max_tokens, temperature, 
                base_url=None):
        """
        æ‰§è¡Œæ‰¹é‡å›¾ç‰‡åˆ†æ
        
        Args:
            images: è¾“å…¥çš„å›¾ç‰‡å¼ é‡åˆ—è¡¨
            prompt: åˆ†ææç¤ºè¯
            api_key: OpenRoute APIå¯†é’¥
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°
            max_tokens: æœ€å¤§è¾“å‡ºtokenæ•°
            temperature: ç”Ÿæˆæ¸©åº¦
            base_url: APIåŸºç¡€URL
            
        Returns:
            batch_results: æ‰¹é‡åˆ†æç»“æœæ–‡æœ¬
        """
        # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤å€¼
        if base_url is None:
            base_url = OPENROUTE_CONFIG["base_url"]
            
        try:
            # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
            client = OpenAI(
                base_url=base_url,
                api_key=api_key
            )
            
            batch_size = images.shape[0]
            results = []
            
            print(f"ğŸ”„ å¼€å§‹æ‰¹é‡å¤„ç† {batch_size} å¼ å›¾ç‰‡...")
            
            for i in range(batch_size):
                try:
                    print(f"ğŸ“¸ æ­£åœ¨å¤„ç†ç¬¬ {i+1}/{batch_size} å¼ å›¾ç‰‡...")
                    
                    # æå–å•å¼ å›¾ç‰‡
                    single_image = images[i:i+1]
                    
                    # è½¬æ¢ä¸ºPILå›¾ç‰‡
                    pil_image = self._tensor_to_pil(single_image)
                    
                    # ç¼–ç ä¸ºbase64
                    base64_image = self._encode_image_to_base64(pil_image)
                    
                    # åˆ›å»ºå›¾ç‰‡å†…å®¹
                    image_content = {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{base64_image}"
                        }
                    }
                    
                    # åˆ›å»ºæ¶ˆæ¯
                    messages = [
                        {
                            "role": "user",
                            "content": [
                                {
                                    "type": "text",
                                    "text": prompt
                                },
                                image_content
                            ]
                        }
                    ]
                    
                    # è°ƒç”¨API
                    completion = client.chat.completions.create(
                        model=model,
                        messages=messages,
                        max_tokens=max_tokens,
                        temperature=temperature
                    )
                    
                    # è·å–åˆ†æç»“æœ
                    result = completion.choices[0].message.content
                    results.append(f"å›¾ç‰‡ {i+1}: {result}")
                    
                    print(f"âœ… ç¬¬ {i+1} å¼ å›¾ç‰‡åˆ†æå®Œæˆ")
                    
                except Exception as e:
                    error_msg = f"å›¾ç‰‡ {i+1} åˆ†æå¤±è´¥: {str(e)}"
                    results.append(error_msg)
                    print(f"âŒ {error_msg}")
                    continue
            
            # åˆå¹¶æ‰€æœ‰ç»“æœ
            batch_results = "\n\n".join(results)
            print(f"ğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆï¼Œå…±å¤„ç† {batch_size} å¼ å›¾ç‰‡")
            
            return (batch_results,)
            
        except Exception as e:
            error_msg = f"æ‰¹é‡å›¾ç‰‡åˆ†æå¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            traceback.print_exc()
            return (error_msg,)
    
    def _tensor_to_pil(self, image_tensor):
        """å°†torchå¼ é‡è½¬æ¢ä¸ºPILå›¾ç‰‡"""
        # ç¡®ä¿å›¾ç‰‡å¼ é‡æ ¼å¼æ­£ç¡® (batch, height, width, channels)
        if len(image_tensor.shape) == 4:
            image_tensor = image_tensor[0]  # å–ç¬¬ä¸€ä¸ªbatch
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„å¹¶ç¡®ä¿å€¼åœ¨0-255èŒƒå›´å†…
        if image_tensor.dtype == torch.float32:
            image_array = (image_tensor.cpu().numpy() * 255).astype(np.uint8)
        else:
            image_array = image_tensor.cpu().numpy().astype(np.uint8)
        
        # åˆ›å»ºPILå›¾ç‰‡
        pil_image = Image.fromarray(image_array)
        return pil_image
    
    def _encode_image_to_base64(self, pil_image, quality=85):
        """å°†PILå›¾ç‰‡ç¼–ç ä¸ºbase64å­—ç¬¦ä¸²"""
        # ç¡®ä¿å›¾ç‰‡æ˜¯RGBæ¨¡å¼
        if pil_image.mode != 'RGB':
            pil_image = pil_image.convert('RGB')
        
        # è½¬æ¢ä¸ºå­—èŠ‚æµ
        img_byte_arr = io.BytesIO()
        pil_image.save(img_byte_arr, format='JPEG', quality=quality, optimize=True)
        img_byte_arr.seek(0)
        
        return base64.b64encode(img_byte_arr.getvalue()).decode('utf-8')

# èŠ‚ç‚¹æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "OpenRouteImageAnalysis": OpenRouteImageAnalysis,
    "OpenRouteBatchImageAnalysis": OpenRouteBatchImageAnalysis,
}

# èŠ‚ç‚¹æ˜¾ç¤ºåç§°æ˜ å°„
NODE_DISPLAY_NAME_MAPPINGS = {
    "OpenRouteImageAnalysis": "OpenRouteå›¾ç‰‡åˆ†æ",
    "OpenRouteBatchImageAnalysis": "OpenRouteæ‰¹é‡å›¾ç‰‡åˆ†æ",
}
